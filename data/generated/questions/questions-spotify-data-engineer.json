{
  "company_slug": "spotify",
  "company_name": "Spotify",
  "role_slug": "data-engineer",
  "role_name": "Data Engineer",
  "generated_at": "2026-01-18T18:36:54.501Z",
  "total_questions": 19,
  "analysis_data": {
    "source_count": 40,
    "themes": [
      "Behavioral interviews important",
      "Multiple interview rounds",
      "Take-home assignment",
      "Panel interviews"
    ],
    "process_insights": {
      "typical_rounds": "4 rounds typical",
      "timeline": "2-4 weeks",
      "format": "Mix of technical, behavioral, on-site, virtual"
    }
  },
  "questions": [
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Tell me about a time you had to lead a project without formal authority.",
      "category": "behavioral",
      "difficulty": "medium",
      "interviewer_intent": "Spotify looks for 'emergent leadership' - people who step up organically without needing titles. Based on 40 interview reports, candidates commonly face: Behavioral interviews important, Multiple interview rounds, Take-home assignment. The interviewer is assessing your influence skills: can you get buy-in from peers? Do you lead through expertise and trust, or do you rely on hierarchy? They're also watching HOW you describe the team - candidates who minimize others' roles reveal poor collaboration instincts that won't work in Spotify's culture.",
      "good_answer_traits": [
        "Influence without authority",
        "Stakeholder management",
        "Self-awareness about leadership style",
        "Credit-sharing with team members",
        "Outcome-focus over ego"
      ],
      "common_mistakes": [
        "Taking all credit (saying 'I' too much, never 'we')",
        "Focusing on the WHAT instead of the HOW of leadership",
        "Describing coercion as influence",
        "Skipping the outcome or metrics"
      ],
      "answer_framework": {
        "structure": "STAR with leadership lens",
        "key_elements": [
          "Why you stepped up (not because you had to)",
          "How you built alignment without authority",
          "Specific influence tactics used",
          "How you handled resistance",
          "Measurable outcome",
          "What you'd do differently"
        ],
        "time_allocation": "Situation: 15%, Task: 10%, Action: 55%, Result: 20%"
      },
      "tags": [
        "leadership",
        "influence",
        "collaboration"
      ],
      "is_premium": false,
      "original_id": "beh-leadership-001"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Describe a time you disagreed with a colleague or manager. How did you handle it?",
      "category": "behavioral",
      "difficulty": "medium",
      "interviewer_intent": "The interviewer is probing your conflict resolution style. Spotify needs people who can disagree constructively - not pushovers, but not bulldozers either. They're listening for: Did you raise the concern or stay silent? Did you attack the person or focus on the idea? Did you know when to commit even if you disagreed? The meta-skill here is 'disagree and commit' - can you advocate strongly, then fully support the decision once made?",
      "good_answer_traits": [
        "Constructive disagreement",
        "Focus on ideas, not personalities",
        "Active listening",
        "Disagree and commit mentality",
        "Professional relationship maintenance"
      ],
      "common_mistakes": [
        "Making the other person look bad",
        "Framing yourself as always right",
        "No resolution or learning",
        "Avoiding the conflict entirely"
      ],
      "answer_framework": {
        "structure": "STAR with resolution focus",
        "key_elements": [
          "The specific disagreement (not vague)",
          "Your perspective AND theirs (shows empathy)",
          "How you raised the concern",
          "The discussion process",
          "The resolution and why it worked",
          "What the relationship looked like after"
        ],
        "time_allocation": "Situation: 20%, Task: 10%, Action: 50%, Result: 20%"
      },
      "tags": [
        "conflict",
        "communication",
        "collaboration"
      ],
      "is_premium": false,
      "original_id": "beh-conflict-002"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Tell me about your biggest professional failure and what you learned from it.",
      "category": "behavioral",
      "difficulty": "hard",
      "interviewer_intent": "Spotify uses this question to assess genuine self-awareness and growth mindset. The interviewer is NOT looking for a humble-brag disguised as failure. They want to see: Can you own a real mistake? Do you understand the root cause, not just the symptoms? Have you actually changed behavior as a result? The best answers show vulnerability and concrete learning - candidates who've 'never really failed' reveal either dishonesty or lack of ambition.",
      "good_answer_traits": [
        "Genuine self-awareness",
        "Accountability without excuses",
        "Root cause analysis",
        "Concrete behavior change",
        "Growth mindset in action"
      ],
      "common_mistakes": [
        "Choosing a fake failure (too small to matter)",
        "Blaming others or circumstances",
        "No actual learning or change",
        "Being defensive when probed"
      ],
      "answer_framework": {
        "structure": "Failure-Analysis-Change-Evidence",
        "key_elements": [
          "The actual failure (be specific and real)",
          "Your role (not just 'we failed')",
          "Root cause analysis",
          "Specific changes you made",
          "Evidence the change stuck",
          "How you'd approach it now"
        ],
        "time_allocation": "Failure: 25%, Analysis: 25%, Change: 35%, Evidence: 15%"
      },
      "tags": [
        "failure",
        "growth",
        "self-awareness"
      ],
      "is_premium": false,
      "original_id": "beh-failure-003"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Tell me about a time you had to make a decision with incomplete information.",
      "category": "behavioral",
      "difficulty": "hard",
      "interviewer_intent": "Spotify operates in uncertainty constantly. The interviewer is testing your comfort with ambiguity: Do you freeze without perfect data, or can you move forward thoughtfully? They're also watching for judgment - did you gather the RIGHT information, not just MORE information? The meta-question is: do you know when 'good enough' data is enough to act, or do you hide behind 'needing more research'?",
      "good_answer_traits": [
        "Comfort with ambiguity",
        "Judgment about what information matters",
        "Bias for action over analysis paralysis",
        "Risk assessment and mitigation",
        "Learning from the outcome"
      ],
      "common_mistakes": [
        "Pretending you had perfect information",
        "Not explaining your reasoning process",
        "No risk mitigation mentioned",
        "Ignoring the outcome or learnings"
      ],
      "answer_framework": {
        "structure": "Context-Decision-Process-Outcome",
        "key_elements": [
          "The ambiguous situation",
          "What information you DID have",
          "What you chose NOT to wait for and why",
          "How you mitigated risk",
          "The decision and rationale",
          "The outcome and what you'd do differently"
        ],
        "time_allocation": "Context: 20%, Process: 40%, Decision: 20%, Outcome: 20%"
      },
      "tags": [
        "ambiguity",
        "decision-making",
        "judgment"
      ],
      "is_premium": false,
      "original_id": "beh-ambiguity-004"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Give me an example of a time you had to work with someone difficult. How did you handle it?",
      "category": "behavioral",
      "difficulty": "medium",
      "interviewer_intent": "The interviewer is probing your interpersonal skills and emotional intelligence. Spotify values collaboration, but they know not everyone is easy to work with. They're watching for: Do you dismiss difficult people or try to understand them? Can you separate the person from the behavior? Do you take ownership of your part in the dynamic? Bonus points if you can describe turning the relationship around.",
      "good_answer_traits": [
        "Emotional intelligence",
        "Empathy for difficult colleagues",
        "Constructive approach to challenges",
        "Self-awareness about your role",
        "Professional relationship management"
      ],
      "common_mistakes": [
        "Making the other person the villain",
        "No empathy for their perspective",
        "Escalating to management too quickly",
        "No resolution or working relationship maintained"
      ],
      "answer_framework": {
        "structure": "STAR with empathy layer",
        "key_elements": [
          "The specific difficulty (behavior, not personality)",
          "Your initial reaction (honest)",
          "How you tried to understand their perspective",
          "Specific tactics you used",
          "The outcome for the work AND the relationship",
          "What you learned about yourself"
        ],
        "time_allocation": "Situation: 15%, Task: 10%, Action: 55%, Result: 20%"
      },
      "tags": [
        "teamwork",
        "emotional-intelligence",
        "conflict"
      ],
      "is_premium": false,
      "original_id": "beh-teamwork-005"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Explain the difference between Type I and Type II errors. When might you prioritize one over the other?",
      "category": "technical",
      "difficulty": "easy",
      "interviewer_intent": "Spotify is testing both your statistical knowledge and your judgment. The textbook answer is easy - they're probing for business intuition. Can you give real-world examples? Do you understand the trade-off between false positives and false negatives? The best answers connect statistics to business impact, not just theory.",
      "good_answer_traits": [
        "Clear understanding of Type I vs. Type II",
        "Real-world examples that resonate",
        "Business judgment about trade-offs",
        "Understanding of sample size implications",
        "Ability to explain to non-technical stakeholders"
      ],
      "common_mistakes": [
        "Only textbook definition without examples",
        "No business context for trade-offs",
        "Confusing the two types",
        "Over-complicating the explanation"
      ],
      "answer_framework": {
        "approach": "Define -> Examples -> Trade-offs -> Business context",
        "key_elements": [
          "Clear definition of both types",
          "Real-world example (spam filter, medical diagnosis)",
          "When to prioritize Type I (false positive) avoidance",
          "When to prioritize Type II (false negative) avoidance",
          "How sample size affects both",
          "How to explain to product managers"
        ],
        "follow_up_prep": "Expect: 'How do you set alpha level for an experiment?' or 'What's the relationship to statistical power?' or 'Give me an example from a project.'"
      },
      "tags": [
        "statistics",
        "hypothesis-testing",
        "fundamentals"
      ],
      "is_premium": true,
      "original_id": "tech-statistics-001"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "You've built a model with 99% accuracy on your test set. What concerns would you have before deploying it?",
      "category": "technical",
      "difficulty": "medium",
      "interviewer_intent": "This question is a trap for candidates who only look at accuracy. Spotify is testing: Do you understand class imbalance? Can you think about real-world deployment issues? Do you consider fairness and edge cases? The 99% number is suspicious and the best candidates immediately ask 'What's the base rate?'",
      "good_answer_traits": [
        "Immediate concern about class imbalance",
        "Understanding of metrics beyond accuracy",
        "Awareness of train/test distribution shift",
        "Fairness and bias considerations",
        "Deployment and monitoring thinking"
      ],
      "common_mistakes": [
        "Taking 99% accuracy at face value",
        "Only considering precision/recall as alternatives",
        "Ignoring fairness and bias concerns",
        "No mention of real-world distribution shift"
      ],
      "answer_framework": {
        "approach": "Question the metric -> Check for issues -> Evaluate for production",
        "key_elements": [
          "What's the base rate? (Class imbalance check)",
          "Precision/recall/F1 for each class",
          "Train/test distribution comparison",
          "Fairness across subgroups",
          "Calibration of probabilities",
          "Monitoring plan post-deployment"
        ],
        "follow_up_prep": "Expect: 'The positive class is 1% of data' or 'How would you handle it if fairness metrics fail?' or 'Walk me through your monitoring plan.'"
      },
      "tags": [
        "machine-learning",
        "metrics",
        "deployment"
      ],
      "is_premium": true,
      "original_id": "tech-ml-002"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Design an A/B test to determine if a new checkout flow increases conversion rate.",
      "category": "technical",
      "difficulty": "medium",
      "interviewer_intent": "Spotify is probing your experimental design skills. They're watching for: Do you define success metrics before the experiment? Can you size the sample correctly? Do you consider confounders and novelty effects? The best answers show a rigorous process, not just 'split traffic 50/50 and check after a week.'",
      "good_answer_traits": [
        "Hypothesis formation before testing",
        "Clear primary and secondary metrics",
        "Sample size calculation",
        "Randomization and validity considerations",
        "Novelty effect awareness"
      ],
      "common_mistakes": [
        "No hypothesis formulation",
        "Skipping sample size calculation",
        "Ignoring novelty effects",
        "Only one metric (no guardrails)"
      ],
      "answer_framework": {
        "approach": "Hypothesis -> Metrics -> Sample size -> Randomization -> Analysis plan",
        "key_elements": [
          "Clear hypothesis (not 'new is better')",
          "Primary metric (conversion rate)",
          "Secondary/guardrail metrics (cart value, returns)",
          "Sample size calculation with MDE",
          "Randomization strategy",
          "Analysis plan including how long to run"
        ],
        "follow_up_prep": "Expect: 'What MDE would you use and why?' or 'How do you handle peeking?' or 'What if results are significant but practical impact is tiny?'"
      },
      "tags": [
        "experimentation",
        "ab-testing",
        "statistics"
      ],
      "is_premium": true,
      "original_id": "tech-experiment-003"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Write a SQL query to find users who have made purchases in consecutive months.",
      "category": "technical",
      "difficulty": "medium",
      "interviewer_intent": "This is a window functions question, but Spotify is testing more than syntax. Can you think through the logic before writing? Do you handle edge cases (first purchase, gaps)? Can you explain your approach clearly? The best candidates talk through their thinking and acknowledge when they'd want to verify with sample data.",
      "good_answer_traits": [
        "Clear problem decomposition",
        "Window function understanding (LAG/LEAD)",
        "Edge case handling",
        "Ability to explain logic clearly",
        "Desire to test with sample data"
      ],
      "common_mistakes": [
        "Jumping to code without planning",
        "Missing edge cases (first month, gaps)",
        "Overly complex solution when simple exists",
        "Not explaining the logic"
      ],
      "answer_framework": {
        "approach": "Understand -> Plan -> Write -> Verify -> Optimize",
        "key_elements": [
          "Clarify: What counts as 'purchase'? Date precision?",
          "Plan: Need to compare each month to previous",
          "LAG function to get previous purchase month",
          "Filter where current - previous = 1 month",
          "Handle: What if multiple purchases in a month?",
          "Verify: Walk through with sample data"
        ],
        "follow_up_prep": "Expect: 'What if we need 3+ consecutive months?' or 'How would you optimize for a large table?' or 'Find users with the longest streak.'"
      },
      "tags": [
        "sql",
        "window-functions",
        "analytics"
      ],
      "is_premium": true,
      "original_id": "tech-sql-004"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Revenue is down 10% month-over-month. How would you diagnose the cause?",
      "category": "technical",
      "difficulty": "hard",
      "interviewer_intent": "Spotify is testing your analytical problem-solving, not just technical skills. Can you structure a complex diagnosis? Do you segment systematically? Do you distinguish correlation from causation? The best answers show a methodical approach and acknowledge that data analysis is iterative, not linear.",
      "good_answer_traits": [
        "Structured diagnostic approach",
        "Segmentation instincts",
        "Correlation vs. causation awareness",
        "Blend of data and intuition",
        "Hypothesis-driven investigation"
      ],
      "common_mistakes": [
        "Random data exploration without structure",
        "Not segmenting (geography, product, user type)",
        "Jumping to conclusions without validation",
        "Ignoring external factors (seasonality, market)"
      ],
      "answer_framework": {
        "approach": "Scope -> Segment -> Hypothesize -> Validate -> Recommend",
        "key_elements": [
          "Confirm the 10% is real (data quality check)",
          "Segment: geography, product, user cohort",
          "Check external factors (seasonality, competitors)",
          "Form hypotheses based on data patterns",
          "Validate with deeper analysis",
          "Recommend action with confidence level"
        ],
        "follow_up_prep": "Expect: 'It's concentrated in one region' or 'New user acquisition is fine but retention is down' or 'What would you recommend to leadership?'"
      },
      "tags": [
        "analytics",
        "diagnosis",
        "business"
      ],
      "is_premium": true,
      "original_id": "tech-business-005"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Tell me about a time you took on something outside your job description because it needed to be done.",
      "category": "culture",
      "difficulty": "medium",
      "interviewer_intent": "Spotify values ownership beyond your immediate role. The interviewer is testing whether you default to 'not my job' or naturally expand scope when needed. They're also probing for how you handled the ambiguity - did you wait for permission or act first? Importantly, they're watching whether you resent the extra work in hindsight or frame it as valuable growth. Authentic ownership means wanting to do it, not just doing it.",
      "good_answer_traits": [
        "Proactive scope expansion",
        "Comfort with ambiguity",
        "Long-term thinking over short-term convenience",
        "Genuine enthusiasm for ownership (not resentment)",
        "Learning from stepping outside comfort zone"
      ],
      "common_mistakes": [
        "Framing it as a burden you had to bear",
        "Taking on things to show off rather than because they mattered",
        "No clear impact or outcome from the extra work",
        "Implying you only do this when asked or incentivized"
      ],
      "answer_framework": {
        "authenticity_check": "Before answering, ask yourself: Would I do this again? If you genuinely wouldn't, pick a different example where you felt energized by the ownership.",
        "key_elements": [
          "Why you noticed the gap (shows awareness)",
          "Why you chose to act vs. escalate (judgment)",
          "How you balanced this with your actual responsibilities",
          "The outcome and what you learned",
          "Whether you'd approach it differently now",
          "How it shaped your view of ownership"
        ],
        "red_flags_to_avoid": [
          "Complaining about the situation or colleagues",
          "Implying you were forced into it",
          "No mention of the result or learning"
        ]
      },
      "tags": [
        "ownership",
        "initiative",
        "scope"
      ],
      "target_value": "Problem Solving",
      "is_premium": false,
      "original_id": "cult-ownership-001"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Describe a time you received critical feedback. How did you respond?",
      "category": "culture",
      "difficulty": "medium",
      "interviewer_intent": "Spotify cultures feedback heavily. The interviewer is assessing your growth mindset in action - not in theory. Can you hear hard truths without getting defensive? Do you actually change, or just nod and continue? They're also watching how you describe the feedback-giver - candidates who subtly discredit the source reveal an inability to learn from others.",
      "good_answer_traits": [
        "Non-defensive reception of feedback",
        "Specific behavior change as a result",
        "Gratitude toward the feedback-giver",
        "Self-awareness about blind spots",
        "Ongoing effort to seek feedback"
      ],
      "common_mistakes": [
        "Subtly discrediting the feedback or source",
        "No actual change in behavior",
        "Framing it as 'they misunderstood me'",
        "Only accepting feedback you already agreed with"
      ],
      "answer_framework": {
        "authenticity_check": "Choose an example where the feedback genuinely stung at first - and you grew from it. Surface-level feedback doesn't reveal much about your growth capacity.",
        "key_elements": [
          "The specific feedback (be concrete)",
          "Your initial reaction (be honest if it stung)",
          "How you processed it",
          "The concrete change you made",
          "Evidence the change stuck",
          "Your relationship with that person now"
        ],
        "red_flags_to_avoid": [
          "Defensiveness about the feedback",
          "Making the feedback-giver look bad",
          "No concrete behavior change"
        ]
      },
      "tags": [
        "growth-mindset",
        "feedback",
        "self-awareness"
      ],
      "target_value": "Growth Mindset",
      "is_premium": false,
      "original_id": "cult-learning-002"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Tell me about a time you advocated for the customer even when it was inconvenient for you or the team.",
      "category": "culture",
      "difficulty": "hard",
      "interviewer_intent": "Spotify tests whether you genuinely put customers first or just say you do. The interviewer is looking for situations where customer focus created tension - with timeline, with a stakeholder, with your own priorities. They're testing: Do you cave under pressure, or find ways to serve the customer AND the business? The authentic version includes the cost you paid.",
      "good_answer_traits": [
        "Genuine customer empathy",
        "Willingness to have difficult conversations",
        "Creative problem-solving to serve customer AND business",
        "Personal cost acknowledged (not martyrdom)",
        "Long-term customer relationship thinking"
      ],
      "common_mistakes": [
        "Story with no real tension or cost",
        "Ignoring legitimate business constraints",
        "Hero narrative without team acknowledgment",
        "Customer focus that actually hurt the customer long-term"
      ],
      "answer_framework": {
        "authenticity_check": "The best examples involve real tension - where the 'easy' path was to deprioritize the customer. If there was no cost, it's not really advocacy.",
        "key_elements": [
          "The customer's situation and why it mattered",
          "The tension with business/team priorities",
          "How you advocated (specific actions)",
          "The cost to you or the team",
          "The outcome for the customer",
          "How you'd balance it differently now"
        ],
        "red_flags_to_avoid": [
          "No real cost or tension in the story",
          "Ignoring that the business also matters",
          "Taking sole credit for a team effort"
        ]
      },
      "tags": [
        "customer-obsession",
        "advocacy",
        "trade-offs"
      ],
      "target_value": "Customer Obsession",
      "is_premium": false,
      "original_id": "cult-customer-003"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Describe your ideal work environment. What kind of culture brings out your best work?",
      "category": "culture",
      "difficulty": "easy",
      "interviewer_intent": "This seems open-ended, but Spotify is probing for authentic fit. They're watching for: Does your described ideal actually match their culture? Are you self-aware about what you need? The risk is saying what you think they want to hear - experienced interviewers spot this. It's better to be honest about your preferences and let both sides assess fit.",
      "good_answer_traits": [
        "Genuine self-awareness about preferences",
        "Specific examples that illustrate the ideal",
        "Acknowledgment of trade-offs in any culture",
        "Flexibility where appropriate",
        "Honest assessment of where you struggle"
      ],
      "common_mistakes": [
        "Saying what you think they want to hear",
        "Being too vague ('I like collaborative environments')",
        "No acknowledgment of trade-offs",
        "Pretending you thrive in all environments"
      ],
      "answer_framework": {
        "authenticity_check": "Be honest. If you discover a mismatch, it's better for both parties. A job where you can't be yourself is not a job worth having.",
        "key_elements": [
          "Specific characteristics you thrive in (with examples)",
          "What you need from management/team",
          "Trade-offs you're willing to make",
          "Environments where you've struggled (honest)",
          "How you've adapted when culture didn't match",
          "Questions you have about their culture"
        ],
        "red_flags_to_avoid": [
          "Generic answers that could apply anywhere",
          "Clearly saying what they want to hear",
          "No self-awareness about limitations"
        ]
      },
      "tags": [
        "culture-fit",
        "self-awareness",
        "authenticity"
      ],
      "target_value": "Work Style Fit",
      "is_premium": false,
      "original_id": "cult-speed-004"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Tell me about a time you changed your mind on something you believed strongly.",
      "category": "culture",
      "difficulty": "medium",
      "interviewer_intent": "Spotify values intellectual humility - the ability to update beliefs based on evidence. The interviewer is testing: Can you hold strong opinions loosely? Do you actually change, or just pretend to? They're watching for the quality of the new evidence and whether you sought it out or resisted it. Candidates who 'never had to change their mind' reveal either arrogance or lack of intellectual ambition.",
      "good_answer_traits": [
        "Genuine belief change (not trivial)",
        "Evidence-based updating",
        "Willingness to admit you were wrong",
        "Active seeking of disconfirming evidence",
        "Humility without self-deprecation"
      ],
      "common_mistakes": [
        "Choosing something trivial",
        "Framing it as 'I was partly right'",
        "No explanation of what convinced you",
        "Being defensive about the original belief"
      ],
      "answer_framework": {
        "authenticity_check": "Choose something you actually believed strongly - and were genuinely wrong about. The strength of the original conviction makes the change more impressive, not less.",
        "key_elements": [
          "The original belief and why you held it",
          "What challenged it (person, evidence, experience)",
          "Your internal process of updating",
          "The new belief and how it's different",
          "How this changed your behavior",
          "What it taught you about your own biases"
        ],
        "red_flags_to_avoid": [
          "Minimizing the original belief",
          "Blaming others for your original position",
          "No genuine change, just 'nuancing'"
        ]
      },
      "tags": [
        "intellectual-humility",
        "growth",
        "open-mindedness"
      ],
      "target_value": "Intellectual Humility",
      "is_premium": false,
      "original_id": "cult-bias-005"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "How many golf balls fit in a school bus?",
      "category": "curveball",
      "difficulty": "medium",
      "interviewer_intent": "The interviewer already knows any reasonable answer is fine - this is about process, not precision. Spotify is evaluating: Can you structure chaos? Do you state assumptions or pretend to know dimensions? Are you comfortable being wrong and adjusting? Senior interviewers specifically watch for whether you challenge the premise ('What size school bus?') vs. accepting it blindly and whether you stay curious rather than anxious.",
      "good_answer_traits": [
        "Structured decomposition of a complex problem",
        "Explicit assumption-stating",
        "Comfort with back-of-envelope math",
        "Willingness to sanity-check and adjust",
        "Maintaining composure and even curiosity"
      ],
      "common_mistakes": [
        "Freezing or saying 'I don't know'",
        "Guessing a random number without showing work",
        "Getting defensive when pushed on assumptions",
        "Over-engineering the calculation"
      ],
      "answer_framework": {
        "composure_tip": "Say: 'I'll estimate this step by step and state my assumptions as I go.' This signals you know what they're looking for and buys you thinking time.",
        "approach": "Estimate container volume -> Estimate object volume -> Divide -> Sanity check",
        "key_elements": [
          "Estimate bus dimensions (state as assumption)",
          "Calculate bus volume in cubic feet",
          "Estimate golf ball diameter and volume",
          "Account for packing efficiency (~60-70%)",
          "Do the division",
          "Sanity check: 'Does this feel reasonable?'"
        ]
      },
      "tags": [
        "estimation",
        "structured-thinking",
        "composure"
      ],
      "question_type": "estimation",
      "is_premium": true,
      "original_id": "curve-estimation-001"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "What's your biggest weakness, and don't give me a fake one.",
      "category": "curveball",
      "difficulty": "hard",
      "interviewer_intent": "The interviewer is testing three things at once: 1) Self-awareness - can you identify a real limitation? 2) Honesty under pressure - will you give a genuine answer when pushed? 3) Growth mindset - do you frame weaknesses as fixed traits or areas of active work? They've explicitly closed the 'I work too hard' escape route at Spotify, so they're watching for authenticity and whether you can be vulnerable without self-sabotage.",
      "good_answer_traits": [
        "Genuine self-awareness",
        "Honesty without self-sabotage",
        "Evidence of working on the weakness",
        "Maturity in discussing limitations",
        "Connecting weakness to role-relevant context"
      ],
      "common_mistakes": [
        "Giving a humble-brag ('I'm a perfectionist')",
        "Naming something that's a dealbreaker for the role",
        "No evidence of growth or mitigation",
        "Getting defensive or flustered by the pressure"
      ],
      "answer_framework": {
        "composure_tip": "The pressure is deliberate - take a breath and remember that honest self-awareness is MORE impressive than a polished non-answer. Genuine vulnerability builds trust.",
        "approach": "Name a real weakness -> Show you've identified it -> Describe mitigation -> Connect to growth",
        "key_elements": [
          "A genuine weakness (not a disguised strength)",
          "Specific example of when it's shown up",
          "What you've done to work on it",
          "Honest acknowledgment of ongoing progress",
          "Why it won't derail you in this role",
          "What you're still learning about yourself"
        ]
      },
      "tags": [
        "self-awareness",
        "honesty",
        "pressure"
      ],
      "question_type": "pressure",
      "is_premium": true,
      "original_id": "curve-pressure-002"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "If you could have dinner with anyone, living or dead, who would it be and why?",
      "category": "curveball",
      "difficulty": "medium",
      "interviewer_intent": "This question seems casual but Spotify uses it to reveal your values and intellectual curiosity. They're not judging the person you pick - they're evaluating WHY. Do you pick someone to impress (Einstein, Mandela) or someone genuinely meaningful to you? Can you articulate what you'd want to learn? The best answers reveal authentic curiosity and values, not what you think sounds impressive.",
      "good_answer_traits": [
        "Authentic choice (not performative)",
        "Clear articulation of why this person",
        "Intellectual curiosity about their perspective",
        "What you'd want to learn or discuss",
        "Willingness to be personal if genuine"
      ],
      "common_mistakes": [
        "Picking someone to sound impressive",
        "No genuine connection or reason",
        "Vague answer without depth",
        "Being unable to explain what you'd discuss"
      ],
      "answer_framework": {
        "composure_tip": "Don't overthink who sounds 'best.' Pick someone you're genuinely curious about, even if it's unexpected. Authenticity beats impressiveness every time.",
        "approach": "Who -> Why them specifically -> What you'd discuss -> What you'd hope to learn",
        "key_elements": [
          "Name someone specific",
          "Why this person (not surface-level reasons)",
          "What questions you'd ask them",
          "What you hope to learn or understand",
          "Connection to something meaningful in your life",
          "Willingness to go deep on your reasoning"
        ]
      },
      "tags": [
        "creativity",
        "values",
        "intellectual-curiosity"
      ],
      "question_type": "hypothetical",
      "is_premium": true,
      "original_id": "curve-hypothetical-003"
    },
    {
      "company_slug": "spotify",
      "role_slug": "data-engineer",
      "question_text": "Design a product for blind people to use a smartphone more easily.",
      "category": "curveball",
      "difficulty": "hard",
      "interviewer_intent": "Spotify is testing user empathy and structured creativity under time pressure. Can you quickly empathize with a user group you may not belong to? Do you ask clarifying questions or make assumptions? They're watching for: Do you consider existing solutions first? Can you identify the real problem before jumping to solutions? Bonus points for acknowledging what you don't know and how you'd learn.",
      "good_answer_traits": [
        "User empathy for a different lived experience",
        "Research instinct (what already exists?)",
        "Problem definition before solution",
        "Structured ideation process",
        "Humility about limitations of your perspective"
      ],
      "common_mistakes": [
        "Jumping to solutions without understanding the problem",
        "Ignoring existing accessibility features",
        "Assuming what blind users want without considering diversity",
        "Patronizing or overly complex solutions"
      ],
      "answer_framework": {
        "composure_tip": "Acknowledge upfront: 'I'm not an expert on accessibility. Let me think through this by first considering what I'd want to learn from actual users.'",
        "approach": "Empathize -> Existing solutions -> Problem definition -> Ideate -> Select -> Acknowledge gaps",
        "key_elements": [
          "Acknowledge your perspective limitation",
          "Consider what already exists (VoiceOver, TalkBack)",
          "Define a specific problem (not 'everything')",
          "Generate 2-3 ideas of varying complexity",
          "Pick one and explain trade-offs",
          "Describe how you'd validate with real users"
        ]
      },
      "tags": [
        "creativity",
        "empathy",
        "product-design"
      ],
      "question_type": "creative",
      "is_premium": true,
      "original_id": "curve-creative-004"
    }
  ]
}